---
title: "Automating fisheries modelling with agentic AI"
bibliography: references.bib
editor: source
format: docx
---

## @campbell2024

Campbell provides the graduate student perspective on using AI for learning statistics and coding and overall finds it to be a helpful tool, but notes some limitations. Key limitations include:

1. **Requirement for extensive knowledge to write good prompts**: In my experience, this is true. It's difficult to balance between writing vague prompts (which don't yield good responses from a beginner's perspective) and writing really good prompts (which means you've basically done the work already). There's a middle ground where experts who know what type of statistical analysis they want to do can describe it accurately, and then AI can helpfully do the coding. However, a beginner user wouldn't be able to do this effectively.

2. **Context poisoning**: They didn't call it this, but noted the idea that sometimes AI gives you the wrong answer, and you can't correct the conversation. This is largely known to be true—once you get a chat going in the wrong direction, you're better off starting a new chat than trying to continue with the current one. This is something I should note in my paper.

## @cooper2024

In the editorial, Cooper et al. discuss the opportunities of using AI for ecological modeling and emphasize the importance of transparency around AI use. I found some of this actually unrealistic because AI use becomes so intertwined with how you work that it's difficult to document line by line what's been done by AI versus what's been done by a human.

Cooper et al. address several uses of AI for coding, including:
- Translating code from other languages
- Explaining code
- Helping write unit tests
- Debugging and fixing errors

They also discuss whether we still need to learn and teach coding, concluding that it remains important. They probably understate the current power of AI when they say we still need to learn how to check code, which I increasingly don't think will be true. However, they are right that teaching coding is important for pedagogical reasons—it helps break problems down into smaller parts and encourages logical, reasoned thinking. Without learning those coding skills, it might be harder to think about how to break problems down into component parts.

## @millard2024

Millard addresses loneliness as an issue, noting that ChatGPT is reducing social interactions because people who would have previously gone to colleagues, postdocs, or other students for help with coding now turn to ChatGPT instead. This reduces opportunities for collaboration, human kindness, and support networks. They suggest some ways this could be addressed. I don't think this paper is as relevant to mine, so I probably don't need to cite it.

## @johnson2024

Johnson raises the issue of pressure to publish with AI, which relates to my work. I should cite this when discussing "supercharged p-hacking" because they also discuss hacking entire papers where people can quickly create similar papers repeatedly. This could create a p-hacking situation but with entire papers. When I discuss p-hacking and AI's ability to run many models on the same data and then pick the best one, I should cite their paper.

